manifest-version = 1

[component]
name = "Amazon Data Firehose"
version = "1.2.0"

category = "data-collection"
subcategory = "warehouse"
documentation = "https://www.edgee.cloud/docs/components/data-collection/amazon-data-firehose"
repository = "https://github.com/edgee-cloud/amazon-data-firehose-component"
icon-path = "firehose.png"
wit-version = "1.0.0"
language = "Rust"
description = '''
# Amazon Data Firehose Component

[https://www.edgee.cloud/edgee/amazon-data-firehose](https://www.edgee.cloud/edgee/amazon-data-firehose)

## Overview

The **Amazon Data Firehose** component by Edgee enables streamlined, server-side streaming of analytics events directly to Amazon’s fully managed Kinesis Data Firehose service.
This integration boosts data delivery reliability by sending your data from the edge, ensuring near real-time ingestion into destinations such as S3, Redshift, OpenSearch, and more.

---

## Key Features & Benefits

### Features

- **Edge-based integration**: Capture and forward events directly from the edge for minimal latency.
- **Supports multiple AWS targets**: Send data to Amazon S3, Redshift, OpenSearch Service, and more.
- **Custom configuration**: Set AWS credentials, region, and Firehose stream name.
- **Seamless JSON payload delivery**: Compatible with standard Firehose ingestion patterns.

### Benefits

- **Scalable streaming**: Harness Firehose’s ability to auto-scale with varying data volumes.
- **Reduced client-side complexity**: No SDKs to embed—manage everything at the edge.
- **Reliable and resilient delivery**: Leverage AWS infrastructure for high availability and managed buffering.
- **Broad data integration**: Easily route analytics into your preferred data lakes or BI platforms.

---

## Use Cases

- Ensure real-time streaming of user interactions (e.g., `track`, `page`) to AWS analytics services.
- Build scalable event pipelines for analytics, monitoring, or BI dashboards.
- Centralize data collection in platforms like S3 for deeper ETL or warehousing.
- Load live event streams into Amazon Redshift for near real-time querying.
- Forward logs or custom metrics to OpenSearch for dashboards and alerting.

---

Additional resources: [Amazon Data Firehose Documentation](https://docs.aws.amazon.com/firehose), [Amazon Data Firehose Features](https://aws.amazon.com/kinesis/data-firehose/features/)
'''

[component.build]
command = "cargo build --target wasm32-wasip2 --release --target-dir ./target && rm -f ./firehose.wasm && mv ./target/wasm32-wasip2/release/amazon_data_firehose_component.wasm ./firehose.wasm"
output_path = "firehose.wasm"


[component.settings.aws_access_key]
title = "Your AWS Access Key"
type = "string"
required = true
secret = true
description = "It corresponds to aws_access_key_id in your credentials file."

[component.settings.aws_secret_key]
title = "Your AWS Secret Access Key"
type = "string"
required = true
secret = true
description = "It corresponds to aws_secret_access_key in your credentials file."

[component.settings.aws_session_token]
title = "Your AWS Session Token (optional)"
type = "string"
secret = true
description = "Useful for tests, not recommended in production because it's short-lived"

[component.settings.aws_region]
title = "Your AWS Region"
type = "string"
required = true
description = "The AWS region short name, such as us-east-1 or eu-west-1."

[component.settings.firehose_stream]
title = "Your Firehose Stream name"
type = "string"
required = true
description = "Simply the delivery stream name. Make sure to avoid leading or ending spaces."
